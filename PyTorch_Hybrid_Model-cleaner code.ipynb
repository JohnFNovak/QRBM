{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import IBMQ\n",
    "# IBMQ.save_account(MY_API_TOKEN)\n",
    "import qiskit\n",
    "qiskit.__version__\n",
    "\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit.quantum_info.operators import Operator\n",
    "from qiskit import(QuantumCircuit, execute, Aer)\n",
    "from qiskit.visualization import plot_histogram\n",
    "from qiskit.extensions import Initialize # Import the Inititialize function\n",
    "from qiskit.aqua.circuits.gates import multi_control_toffoli_gate\n",
    "from qiskit.aqua.circuits.gates import multi_control_multi_target_gate\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Function\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline   \n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from skimage import data, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage import img_as_bool\n",
    "\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exctract_single_qubit_measurment(dict_of_counts, qubit_range):\n",
    "#     print(dict_of_counts)\n",
    "#     print(len(list(dict_of_counts.keys())[0]))\n",
    "    num_qubits = len(list(dict_of_counts.keys())[0])\n",
    "#     result = np.zeros(len(qubit_range))\n",
    "    result = np.zeros(num_qubits)\n",
    "#     print(result)\n",
    "    for el in dict_of_counts:\n",
    "        for i in range(num_qubits):\n",
    "#             print(\"i\", i)\n",
    "#             print(\"el[i]\", el[i])\n",
    "            if i in qubit_range and el[i] == '1':\n",
    "                result[i] += dict_of_counts[el]\n",
    "#     print(result)\n",
    "#     print(result[qubit_range])\n",
    "    return result[qubit_range]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wczytywanie danych inną metodą\n",
    "# Concentrating on the first 100 samples\n",
    "n_samples = 100\n",
    "\n",
    "X_train = datasets.MNIST(root='./data', train=True, download=True,\n",
    "                         transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "# Leaving only labels 0 and 1 \n",
    "idx = np.append(np.where(X_train.targets == 0)[0][:n_samples], \n",
    "                np.where(X_train.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_train.data = X_train.data[idx]\n",
    "X_train.targets = X_train.targets[idx]\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(X_train, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "\n",
    "data_iter = iter(train_loader)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "while n_samples_show > 0:\n",
    "    images, targets = data_iter.__next__()\n",
    "\n",
    "    axes[n_samples_show - 1].imshow(images[0].numpy().squeeze(), cmap='gray')\n",
    "    axes[n_samples_show - 1].set_xticks([])\n",
    "    axes[n_samples_show - 1].set_yticks([])\n",
    "    axes[n_samples_show - 1].set_title(\"Labeled: {}\".format(targets.item()))\n",
    "    \n",
    "    n_samples_show -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "\n",
    "X_test = datasets.MNIST(root='./data', train=False, download=True,\n",
    "                        transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "idx = np.append(np.where(X_test.targets == 0)[0][:n_samples], \n",
    "                np.where(X_test.targets == 1)[0][:n_samples])\n",
    "\n",
    "X_test.data = X_test.data[idx]\n",
    "X_test.targets = X_test.targets[idx]\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(X_test, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QMLCircuit():\n",
    "    def __init__(self, visible, hidden, num_shots=1000):\n",
    "        self.visible = visible\n",
    "        self.hidden = hidden\n",
    "        self.ancilla = visible-1\n",
    "        self.qr = QuantumRegister((self.visible + self.hidden + self.ancilla), 'q')\n",
    "        self.cr = ClassicalRegister(self.hidden, 'c')\n",
    "        self.qc = QuantumCircuit(self.qr, self.cr)\n",
    "\n",
    "        self.num_shots = num_shots\n",
    "    \n",
    "#     def run(self, thetas):\n",
    "    def circuit_function(self, x, weight_matrix):\n",
    "        self.qc.data = []\n",
    "        print(\"x: \",x)\n",
    "        print(\"x[0]: \", x[0])\n",
    "\n",
    "        # inicjalizacja wartości qubitów wejściowych (x)\n",
    "        initial_state = [[np.sqrt(1-x[i]*x[i]), x[i]] for i in range(len(x))]\n",
    "\n",
    "        # inicjalizacja wartości qubitów wejściowych i bramka Hadamarda\n",
    "        for i in range(visible):\n",
    "            initialize_qubit = Initialize(initial_state[i])\n",
    "            self.qc.append(initialize_qubit, [i])\n",
    "            self.qc.h(i)\n",
    "\n",
    "        # ciąg bramek CNOT i bramek rotacji R (zależnych od parametrów)\n",
    "        for i in range(self.hidden):\n",
    "            for j in range(self.visible):\n",
    "                self.qc.ry(weight_matrix[j][i], j)\n",
    "            print([self.qr[k] for k in range(self.visible)])\n",
    "            print(self.qr[self.visible + i])\n",
    "            print([self.qr[i] for i in range(self.visible + self.hidden, self.visible + self.hidden + self.ancilla)])\n",
    "            multi_control_toffoli_gate.mct(self.qc, [self.qr[k] for k in range(self.visible)], self.qr[self.visible + i], [self.qr[i] for i in range(self.visible + self.hidden, self.visible + self.hidden + self.ancilla)], mode='basic')\n",
    "\n",
    "        # pomiar linii visible\n",
    "        self.qc.measure(list(range(self.visible, self.visible+self.hidden)), list(range(self.hidden)))\n",
    "\n",
    "        #eksperyment:\n",
    "        simulator = Aer.get_backend('qasm_simulator')\n",
    "        job = execute(self.qc, simulator, shots=self.num_shots)\n",
    "        result = job.result()\n",
    "        counts = result.get_counts(self.qc)\n",
    "        ph = exctract_single_qubit_measurment(counts, list(range(self.hidden))) / self.num_shots\n",
    "    #     print(\"\\nProbabilities are:\",ph)\n",
    "        return ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x:  [0.99737464 0.30191177]\n",
      "x[0]:  0.9973746427348991\n",
      "[Qubit(QuantumRegister(4, 'q'), 0), Qubit(QuantumRegister(4, 'q'), 1)]\n",
      "Qubit(QuantumRegister(4, 'q'), 2)\n",
      "[Qubit(QuantumRegister(4, 'q'), 3)]\n",
      "[0.339]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌──────────────────────────────┐┌───┐┌────────────┐        \n",
       "q_0: |0>┤ Initialize(0.072414,0.99737) ├┤ H ├┤ Ry(2.7839) ├──■─────\n",
       "        ├─────────────────────────────┬┘├───┤├────────────┤  │     \n",
       "q_1: |0>┤ Initialize(0.95334,0.30191) ├─┤ H ├┤ Ry(2.9774) ├──■─────\n",
       "        └─────────────────────────────┘ └───┘└────────────┘┌─┴─┐┌─┐\n",
       "q_2: |0>───────────────────────────────────────────────────┤ X ├┤M├\n",
       "                                                           └───┘└╥┘\n",
       "q_3: |0>─────────────────────────────────────────────────────────╫─\n",
       "                                                                 ║ \n",
       " c_0: 0 ═════════════════════════════════════════════════════════╩═\n",
       "                                                                   </pre>"
      ],
      "text/plain": [
       "        ┌──────────────────────────────┐┌───┐┌────────────┐        \n",
       "q_0: |0>┤ Initialize(0.072414,0.99737) ├┤ H ├┤ Ry(2.7839) ├──■─────\n",
       "        ├─────────────────────────────┬┘├───┤├────────────┤  │     \n",
       "q_1: |0>┤ Initialize(0.95334,0.30191) ├─┤ H ├┤ Ry(2.9774) ├──■─────\n",
       "        └─────────────────────────────┘ └───┘└────────────┘┌─┴─┐┌─┐\n",
       "q_2: |0>───────────────────────────────────────────────────┤ X ├┤M├\n",
       "                                                           └───┘└╥┘\n",
       "q_3: |0>─────────────────────────────────────────────────────────╫─\n",
       "                                                                 ║ \n",
       " c_0: 0 ═════════════════════════════════════════════════════════╩═\n",
       "                                                                   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visible = 2\n",
    "hidden = 1\n",
    "    \n",
    "QMLC = QMLCircuit(visible, hidden, 1000)\n",
    "#definicja wejścia (x)oraz inicjalizacja macierzy wag\n",
    "x = np.array([random.uniform(0, 1) for n in range(visible)])\n",
    "weight_matrix = np.random.rand(visible, hidden) * np.pi\n",
    "print(QMLC.circuit_function(x, weight_matrix))\n",
    "QMLC.qc.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QFunction(Function):\n",
    "    \"\"\" Hybrid quantum - classical function definition \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward(ctx, input, QMLC, epsilon, weight_matrix):\n",
    "        \"\"\" Forward pass computation \"\"\"\n",
    "        ctx.epsilon = epsilon\n",
    "        ctx.QMLC = QMLC\n",
    "        ctx.weight_matrix = weight_matrix\n",
    "        print(\"input from forward: \", input)\n",
    "        \n",
    "        print(type(ctx.weight_matrix))\n",
    "        \n",
    "        wm = ctx.weight_matrix.tolist()\n",
    "        print(wm)\n",
    "        print(type(wm))\n",
    "        \n",
    "        ph = ctx.QMLC.circuit_function(input.tolist()[0], wm)\n",
    "        \n",
    "        print(\"halo\")\n",
    "        \n",
    "        result = torch.tensor([ph])\n",
    "        print(\"result: \", result)\n",
    "        ctx.save_for_backward(input, result)\n",
    "        return result\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "#     def update(ph, expected_ph, weight_matrix, lr):\n",
    "\n",
    "        input, ph = ctx.saved_tensors\n",
    "        input_list = np.array(input.tolist())\n",
    "        wm = ctx.weight_matrix.tolist()\n",
    "\n",
    "        print(\"wm: \", wm)\n",
    "        print(len(wm))\n",
    "        print(len(wm[0]))\n",
    "        gradient = []\n",
    "        for i in range(len(wm)):\n",
    "            gradient_row = []\n",
    "            for j in range(len(wm[0])):\n",
    "                print(\"halo\")\n",
    "                wm[i][j] += ctx.epsilon\n",
    "                result_plus = ctx.QMLC.circuit_function(input_list.tolist()[0], wm)\n",
    "\n",
    "                wm[i][j] -= 2*ctx.epsilon\n",
    "                result_minus = ctx.QMLC.circuit_function(input_list.tolist()[0], wm)\n",
    "\n",
    "                wm[i][j] += ctx.epsilon\n",
    "    #             print(\"exp_ph\", expected_ph)\n",
    "    #             print(result_plus - result_minus)\n",
    "                result = (result_plus - result_minus)/(2*ctx.epsilon) * 1\n",
    "                gradient_row.append(result)\n",
    "            gradient.append(gradient_row)\n",
    "#         return gradient\n",
    "        print(\"gradient: \", gradient)\n",
    "        gradient = np.array(gradient).T\n",
    "        print(torch.tensor(gradient).float() * grad_output.float(), None, None)\n",
    "        return torch.tensor(gradient).float() * grad_output.float(), None, None, None\n",
    "        \n",
    "        \n",
    "#         \"\"\" Backward pass computation \"\"\"\n",
    "#         input, ph = ctx.saved_tensors\n",
    "#         input_list = np.array(input.tolist())\n",
    "        \n",
    "#         shift_right = input_list + np.ones(input_list.shape) * ctx.epsilon\n",
    "#         shift_left = input_list - np.ones(input_list.shape) * ctx.epsilon\n",
    "        \n",
    "#         gradients = []\n",
    "#         for i in range(len(input_list)):\n",
    "#             expectation_right = ctx.quantum_circuit.run(shift_right[i])\n",
    "#             expectation_left  = ctx.quantum_circuit.run(shift_left[i])\n",
    "            \n",
    "#             gradient = torch.tensor([expectation_right]) - torch.tensor([expectation_left])\n",
    "#             gradients.append(gradient)\n",
    "#         gradients = np.array([gradients]).T\n",
    "#         return torch.tensor([gradients]).float() * grad_output.float(), None, None\n",
    "\n",
    "class QuantumLayer(nn.Module):\n",
    "    \"\"\" Hybrid quantum - classical layer definition \"\"\"\n",
    "    \n",
    "    def __init__(self, backend, shots, epsilon):\n",
    "        super(QuantumLayer, self).__init__()\n",
    "        self.QMLC = QMLCircuit(1, 1, 1000)\n",
    "        self.epsilon = epsilon\n",
    "#         self.weight_matrix = nn.Parameter(torch.randn(visible, hidden))\n",
    "        self.weight_matrix = np.random.rand(visible, hidden) * np.pi\n",
    "        print(\"self.weight_matrix: \", self.weight_matrix)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return QFunction.apply(input, self.QMLC, self.epsilon, self.weight_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(6400, 64)\n",
    "        self.fc2 = nn.Linear(64, 2)\n",
    "        self.quantum = QuantumLayer(qiskit.Aer.get_backend('qasm_simulator'), 1000, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(-1, 6400)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.quantum(x)\n",
    "        return torch.cat((x, 1 - x), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.weight_matrix:  [[2.45386972]\n",
      " [1.37076981]]\n",
      "input from forward:  tensor([[ 0.0165, -0.0848]], grad_fn=<AddmmBackward>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[2.4538697219031564], [1.3707698059825242]]\n",
      "<class 'list'>\n",
      "x:  [0.01651553250849247, -0.08477959036827087]\n",
      "x[0]:  0.01651553250849247\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "result:  tensor([[0.4480]], dtype=torch.float64)\n",
      "wm:  [[2.4538697219031564], [1.3707698059825242]]\n",
      "2\n",
      "1\n",
      "halo\n",
      "x:  [0.01651553250849247, -0.08477959036827087]\n",
      "x[0]:  0.01651553250849247\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [0.01651553250849247, -0.08477959036827087]\n",
      "x[0]:  0.01651553250849247\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "x:  [0.01651553250849247, -0.08477959036827087]\n",
      "x[0]:  0.01651553250849247\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [0.01651553250849247, -0.08477959036827087]\n",
      "x[0]:  0.01651553250849247\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "gradient:  [[array([-0.8])], [array([-0.45])]]\n",
      "tensor([[[0.8000, 0.4500]]]) None None\n",
      "input from forward:  tensor([[-0.1133, -0.1579]], grad_fn=<AddmmBackward>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[2.4538697219031564], [1.3707698059825242]]\n",
      "<class 'list'>\n",
      "x:  [-0.11333706974983215, -0.1578713059425354]\n",
      "x[0]:  -0.11333706974983215\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "result:  tensor([[0.4290]], dtype=torch.float64)\n",
      "wm:  [[2.4538697219031564], [1.3707698059825242]]\n",
      "2\n",
      "1\n",
      "halo\n",
      "x:  [-0.11333706974983215, -0.1578713059425354]\n",
      "x[0]:  -0.11333706974983215\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.11333706974983215, -0.1578713059425354]\n",
      "x[0]:  -0.11333706974983215\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "x:  [-0.11333706974983215, -0.1578713059425354]\n",
      "x[0]:  -0.11333706974983215\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.11333706974983215, -0.1578713059425354]\n",
      "x[0]:  -0.11333706974983215\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "gradient:  [[array([0.6])], [array([-0.25])]]\n",
      "tensor([[[ 0.6000, -0.2500]]]) None None\n",
      "input from forward:  tensor([[-0.4932, -0.2546]], grad_fn=<AddmmBackward>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[2.4538697219031564], [1.3707698059825242]]\n",
      "<class 'list'>\n",
      "x:  [-0.4931914806365967, -0.25459009408950806]\n",
      "x[0]:  -0.4931914806365967\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "result:  tensor([[0.5600]], dtype=torch.float64)\n",
      "wm:  [[2.4538697219031564], [1.3707698059825242]]\n",
      "2\n",
      "1\n",
      "halo\n",
      "x:  [-0.4931914806365967, -0.25459009408950806]\n",
      "x[0]:  -0.4931914806365967\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.4931914806365967, -0.25459009408950806]\n",
      "x[0]:  -0.4931914806365967\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "x:  [-0.4931914806365967, -0.25459009408950806]\n",
      "x[0]:  -0.4931914806365967\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.4931914806365967, -0.25459009408950806]\n",
      "x[0]:  -0.4931914806365967\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "gradient:  [[array([0.1])], [array([0.8])]]\n",
      "tensor([[[0.1000, 0.8000]]]) None None\n",
      "input from forward:  tensor([[-0.7209, -0.4103]], grad_fn=<AddmmBackward>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[2.4538697219031564], [1.3707698059825242]]\n",
      "<class 'list'>\n",
      "x:  [-0.7208684682846069, -0.410317063331604]\n",
      "x[0]:  -0.7208684682846069\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "result:  tensor([[0.7940]], dtype=torch.float64)\n",
      "wm:  [[2.4538697219031564], [1.3707698059825242]]\n",
      "2\n",
      "1\n",
      "halo\n",
      "x:  [-0.7208684682846069, -0.410317063331604]\n",
      "x[0]:  -0.7208684682846069\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.7208684682846069, -0.410317063331604]\n",
      "x[0]:  -0.7208684682846069\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "halo\n",
      "x:  [-0.7208684682846069, -0.410317063331604]\n",
      "x[0]:  -0.7208684682846069\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "x:  [-0.7208684682846069, -0.410317063331604]\n",
      "x[0]:  -0.7208684682846069\n",
      "[Qubit(QuantumRegister(2, 'q'), 0)]\n",
      "Qubit(QuantumRegister(2, 'q'), 1)\n",
      "[]\n",
      "gradient:  [[array([1.45])], [array([0.05])]]\n",
      "tensor([[[1.4500, 0.0500]]]) None None\n",
      "input from forward:  tensor([[-1.0723, -0.4969]], grad_fn=<AddmmBackward>)\n",
      "<class 'numpy.ndarray'>\n",
      "[[2.4538697219031564], [1.3707698059825242]]\n",
      "<class 'list'>\n",
      "x:  [-1.0722966194152832, -0.49686959385871887]\n",
      "x[0]:  -1.0722966194152832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\mateusz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\ipykernel_launcher.py:19: RuntimeWarning: invalid value encountered in sqrt\n"
     ]
    },
    {
     "ename": "QiskitError",
     "evalue": "'Sum of amplitudes-squared does not equal one.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mQiskitError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-86-1e26186df8ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# Forward pass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m# Calculating loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateusz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-84-b06d96113533>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquantum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateusz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-83-05c923738cef>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mQFunction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQMLC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight_matrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-83-05c923738cef>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, input, QMLC, epsilon, weight_matrix)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQMLC\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcircuit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"halo\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-11dac93286fc>\u001b[0m in \u001b[0;36mcircuit_function\u001b[1;34m(self, x, weight_matrix)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# inicjalizacja wartości qubitów wejściowych i bramka Hadamarda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvisible\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0minitialize_qubit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialize_qubit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mateusz\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\qiskit\\extensions\\quantum_initializer\\initializer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m     54\u001b[0m         if not math.isclose(sum(np.absolute(params) ** 2), 1.0,\n\u001b[0;32m     55\u001b[0m                             abs_tol=_EPS):\n\u001b[1;32m---> 56\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mQiskitError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Sum of amplitudes-squared does not equal one.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mnum_qubits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_qubits\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mQiskitError\u001b[0m: 'Sum of amplitudes-squared does not equal one.'"
     ]
    }
   ],
   "source": [
    "# trenowanie modelu\n",
    "\n",
    "model = Net()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_func = nn.NLLLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    total_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         target = target.float() # for MSELoss() function\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        output = model(data)\n",
    "        # Calculating loss\n",
    "        loss = loss_func(output, target)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        # Optimize the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    loss_list.append(sum(total_loss)/len(total_loss))\n",
    "    print('Training [{:.0f}%]\\tLoss: {:.4f}'.format(\n",
    "        100. * (epoch + 1) / epochs, loss_list[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Neg Log Likelihood Loss')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance on test data:\n",
      "\tLoss: -47457742664.0000\n",
      "\tAccuracy: 98.0%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    \n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        \n",
    "        loss = loss_func(output, target)\n",
    "        total_loss.append(loss.item())\n",
    "        \n",
    "    print('Performance on test data:\\n\\tLoss: {:.4f}\\n\\tAccuracy: {:.1f}%'.format(\n",
    "        sum(total_loss) / len(total_loss),\n",
    "        correct / len(test_loader) * 100)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_samples_show = 6\n",
    "count = 0\n",
    "fig, axes = plt.subplots(nrows=1, ncols=n_samples_show, figsize=(10, 3))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        if count == n_samples_show:\n",
    "            break\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True) \n",
    "\n",
    "        axes[count].imshow(data[0].numpy().squeeze(), cmap='gray')\n",
    "\n",
    "        axes[count].set_xticks([])\n",
    "        axes[count].set_yticks([])\n",
    "        axes[count].set_title('Predicted {}'.format(pred.item()))\n",
    "        \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nie trzeba odpalać STARE FUNKCJE\n",
    "epsilon = 0.01\n",
    "def update(ph, expected_ph, weight_matrix, lr):\n",
    "    gradient = []\n",
    "    for i, row in enumerate(weight_matrix):\n",
    "        gradient_row = []\n",
    "        for j, el in enumerate(row):\n",
    "            weight_matrix[i][j] += epsilon\n",
    "            result_plus = circuit_function(qc, weight_matrix)\n",
    "\n",
    "            weight_matrix[i][j] -= 2*epsilon\n",
    "            result_minus = circuit_function(qc, weight_matrix)\n",
    "\n",
    "            weight_matrix[i][j] += epsilon\n",
    "#             result_zero = circuit_function(qc, weight_matrix)\n",
    "#             print(\"ph\", result_zero)\n",
    "#             print(\"exp_ph\", expected_ph)\n",
    "#             print(\"el final:\", el)\n",
    "#             print(result_plus - result_minus)\n",
    "            result = (result_plus - result_minus)/(2*epsilon) * lr * (ph - expected_ph)\n",
    "            gradient_row.append(result)\n",
    "        gradient.append(gradient_row)\n",
    "#     print(\"gradient\", gradient)\n",
    "\n",
    "    weight_matrix = weight_matrix - gradient\n",
    "    return weight_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'x': array([1, 1]), 'y': 0}, {'x': array([0, 0]), 'y': 0}, {'x': array([0, 1]), 'y': 1}, {'x': array([1, 1]), 'y': 0}]\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(dataset_size):\n",
    "    dataset = []\n",
    "    for i in range(dataset_size):\n",
    "        x = np.array([random.choice([0,1]), random.choice([0,1])])\n",
    "        y = 1\n",
    "        if np.array_equal(x, np.array([0,0])) or np.array_equal(x, np.array([1,1])):\n",
    "            y = 0\n",
    "        dataset.append({\"x\": x, \"y\": y})\n",
    "    return dataset\n",
    "\n",
    "dataset = create_dataset(4)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-5b755048f991>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# x = np.array([random.uniform(0, 1) for n in range(visible)])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# template do uczenia\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#definicja rozmiaru sieci\n",
    "visible = 2\n",
    "hidden = 1\n",
    "ancilla = visible-1\n",
    "\n",
    "#definicja wejścia (x)oraz inicjalizacja macierzy wag\n",
    "# x = np.array([random.uniform(0, 1) for n in range(visible)])\n",
    "\n",
    "dataset = create_dataset(10)\n",
    "print(dataset[0][\"x\"][0])\n",
    "print(dataset[0][\"x\"][1])\n",
    "print([n for n in range(visible)])\n",
    "\n",
    "\n",
    "weight_matrix = np.random.rand(visible, hidden) * np.pi\n",
    "\n",
    "#definicja parametrów uczenia\n",
    "num_shots = 1000\n",
    "num_epochs = 100\n",
    "qr = QuantumRegister(visible + hidden + ancilla, 'q')\n",
    "cr = ClassicalRegister(hidden, 'c')\n",
    "qc = QuantumCircuit(qr, cr)\n",
    "\n",
    "cost_function_data = []\n",
    "lr = 0.05\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(\"epoch: \", epoch)\n",
    "    for i, element in enumerate(dataset):\n",
    "#         print(element)\n",
    "        x = np.array([dataset[i][\"x\"][n] for n in range(visible)])\n",
    "        exp_ph = dataset[i][\"y\"]\n",
    "        ph = circuit_function(qc, weight_matrix)\n",
    "        weight_matrix = update(ph, exp_ph, weight_matrix, lr)\n",
    "#         print(\"exp_ph\", exp_ph, \"ph\", ph, \"weight_matrix\", weight_matrix, \"cost_function\", 0.5 * (ph - exp_ph)**2)   \n",
    "    cost_function_data.append(0.5 * (ph - exp_ph)**2)\n",
    "qc.draw()\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('cost')\n",
    "plt.plot(cost_function_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03\n",
      "0 \n",
      "\n",
      "0.917\n",
      "1 \n",
      "\n",
      "0.045\n",
      "0 \n",
      "\n",
      "0.912\n",
      "1 \n",
      "\n",
      "0.909\n",
      "1 \n",
      "\n",
      "0.029\n",
      "0 \n",
      "\n",
      "0.053\n",
      "0 \n",
      "\n",
      "0.041\n",
      "0 \n",
      "\n",
      "0.034\n",
      "0 \n",
      "\n",
      "0.038\n",
      "0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    x = np.array([dataset[i][\"x\"][n] for n in range(visible)])\n",
    "    exp_ph = dataset[i][\"y\"]\n",
    "    ph = circuit_function(qc, weight_matrix)\n",
    "    print(ph)\n",
    "    print(exp_ph, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"word-wrap: normal;white-space: pre;background: #fff0;line-height: 1.1;font-family: &quot;Courier New&quot;,Courier,monospace\">        ┌─────────────────┐┌───┐┌────────────┐        \n",
       "q_0: |0>┤ Initialize(0,1) ├┤ H ├┤ Ry(1.1361) ├──■─────\n",
       "        ├─────────────────┤├───┤├────────────┤  │     \n",
       "q_1: |0>┤ Initialize(0,1) ├┤ H ├┤ Ry(4.3279) ├──■─────\n",
       "        └─────────────────┘└───┘└────────────┘┌─┴─┐┌─┐\n",
       "q_2: |0>──────────────────────────────────────┤ X ├┤M├\n",
       "                                              └───┘└╥┘\n",
       "q_3: |0>────────────────────────────────────────────╫─\n",
       "                                                    ║ \n",
       " c_0: 0 ════════════════════════════════════════════╩═\n",
       "                                                      </pre>"
      ],
      "text/plain": [
       "<qiskit.visualization.text.TextDrawing at 0x7fbb1f4d74a8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qc.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031\n"
     ]
    }
   ],
   "source": [
    "ph = circuit_function(qc, weight_matrix)\n",
    "print(ph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
